# Project 6: Web Scraping and NLP

This repository contains code and notebooks for practicing web scraping (fetching and extracting information) and processing content from web pages using Natural Language Processing (NLP) techniques.

## Objectives

This exercise aims to practice the following:

- Web scraping to fetch and extract information from web pages.
- Processing content using NLP techniques.
- Documenting and sharing code and notebooks on GitHub.

See [BeautifulSoup Quickstart Guide](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start)

Choose a BeautifulSoup parser:

- 'html.parser' (default, you get this with BeautifulSoup)
- 'html5lib' (install separately if desired)

## Getting Started

To get started with web scraping, follow these steps:

### 1. Fork and Clone Repository

```bash
# Fork the repository by clicking the "Fork" button on the GitHub repository page.
# Clone the forked repository to your local machine.
git clone https://github.com/your_username/web-scraping.git
cd web-scraping
```
### 2. Create and activate a virtual environment

Create the environment:

```bash
py -m venv .venv
```

Activate the environment:

```bash
source .venv\Scripts\activate
```

## 3. Install Requirements

The project depends on the following packages. 

- collections
- pickle
- requests
- spacy
- bs4 (BeautifulSoup)
- matplotlib.pyplot


You can install them using pip:

```bash
pip install -r requirements.txt
```

## Sources

The following link provides the original documentation that was used as a reference for this project:

- (https://github.com/denisecase/620-mod6-web-scraping)


